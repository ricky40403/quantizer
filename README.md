# quantizer

----
Propose:
* for personal study.  
* organize the quantization, which can help others to conveniently transform their model to quantized model  for testing

## Support 
Currently support 
* None


## Target
[ ] Parsing Model's modele
[ ] Merge and convert layers
[ ] Adding 8 bit converting 
[ ] Adding 16 bit converting 
[ ] Adding 8 ~ 16 bit converting 
[ ] Seperate as  Fake quantization for training and true quantization for testing.
